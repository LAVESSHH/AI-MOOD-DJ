import cv2
from pygame import mixer
import tkinter as tk
import os
import sys
import time
import numpy as np

# ---------- SONGS ----------
MOOD_SONGS = {
    "happy": "songs/happy.mp3",
    "neutral": "songs/lofi.mp3",
    "sad": "songs/sad.mp3"
}
mixer.init()

def play_song(mood):
    song = MOOD_SONGS.get(mood, "songs/lofi.mp3")
    if os.path.exists(song):
        mixer.music.stop()
        mixer.music.load(song)
        mixer.music.play(-1)
        print(f"[INFO] Playing {mood} song â†’ {song}")
    else:
        print(f"[WARN] Missing file: {song}")

# ---------- STEP 1: HAND DETECTION ----------
def hand_detection_trigger(timeout=10):
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("[ERROR] Cannot access camera.")
        return False

    frame_w, frame_h = 640, 480
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_w)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_h)

    top_left = (frame_w//2 - 100, frame_h//2 - 100)
    bottom_right = (frame_w//2 + 100, frame_h//2 + 100)

    start_time = time.time()
    print("[INFO] Place your hand inside the green rectangle to start...")

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame = cv2.flip(frame, 1)
        cv2.rectangle(frame, top_left, bottom_right, (0,255,0), 3)
        cv2.putText(frame, "Place hand here", (top_left[0], top_left[1]-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)

        # Extract ROI and detect hand using skin color + contour
        roi = frame[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]
        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
        lower_skin = np.array([0, 20, 70], dtype=np.uint8)
        upper_skin = np.array([20, 255, 255], dtype=np.uint8)
        mask = cv2.inRange(hsv, lower_skin, upper_skin)
        mask = cv2.GaussianBlur(mask, (5,5), 0)
        _, thresh = cv2.threshold(mask, 0, 255, cv2.THRESH_BINARY)
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        hand_detected = False
        for cnt in contours:
            if cv2.contourArea(cnt) > 3000:
                hand_detected = True
                break

        if hand_detected:
            print("[INFO] Hand detected! Proceeding to Step 2 in 3 seconds...")
            cap.release()
            cv2.destroyAllWindows()
            time.sleep(3)
            return True

        cv2.imshow("Step 1: Hand Detection", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

        if time.time() - start_time > timeout:
            print("[INFO] Hand not detected within 10 seconds. Exiting...")
            cap.release()
            cv2.destroyAllWindows()
            return False

# ---------- STEP 2: FACE & MOOD DETECTION ----------
def face_mood_detection():
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
    smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_smile.xml")
    cap = cv2.VideoCapture(0)
    prev_mood = None
    last_change_time = time.time()
    song_delay = 3  # Minimum delay in seconds between song changes

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame = cv2.flip(frame, 1)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)
        mood = "neutral"

        for (x, y, w, h) in faces:
            face_roi = gray[y:y+h, x:x+w]
            smiles = smile_cascade.detectMultiScale(face_roi, 1.8, 20)
            mood = "happy" if len(smiles) > 0 else "sad"
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255,0), 2)
            cv2.putText(frame, f"Mood: {mood}", (x, y-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)

        # Change song only if mood changes and 3s passed
        if mood != prev_mood and time.time() - last_change_time > song_delay:
            play_song(mood)
            prev_mood = mood
            last_change_time = time.time()

        cv2.imshow("Step 2: Face & Mood Detection", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

# ---------- GUI ----------
def start_gui():
    def proceed():
        root.destroy()
        if hand_detection_trigger(timeout=10):
            face_mood_detection()

    root = tk.Tk()
    root.title("AI Mood DJ")
    root.geometry("600x400")
    root.configure(bg="#111")

    tk.Label(root, text="ðŸŽ§ AI Mood DJ", bg="#111", fg="#00ffcc",
             font=("Poppins", 26, "bold")).pack(pady=40)
    tk.Label(root, text="Wave your hand inside the rectangle to start.",
             bg="#111", fg="#ccc", font=("Poppins", 12)).pack(pady=10)

    tk.Button(root, text="Proceed", bg="#00bcd4", fg="white",
              font=("Poppins", 14, "bold"), relief="flat",
              padx=20, pady=10, command=proceed).pack(pady=50)

    root.mainloop()

# ---------- RUN ----------
if __name__ == "__main__":
    start_gui()
